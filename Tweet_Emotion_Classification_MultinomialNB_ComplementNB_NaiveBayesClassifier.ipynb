{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indonesian Tweet Emotion Classification Using Naive Bayes Classifiers on MultinomialNB and ComplementNB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library\n",
    "\n",
    "in this project i used:\n",
    "1. pandas, data manipulation and analysist\n",
    "2. numpy, change the data into an array\n",
    "3. re, find some pattern in strings\n",
    "4. string, string manipulation\n",
    "5. Sastrawi, remove stopword\n",
    "6. LabelEncoder, preprocessing some column to make it into numerics\n",
    "7. train_test_split, spliting data into data train and test train\n",
    "8. CountVectorizer and TfidfTransformer, data preparation\n",
    "9. classification_report, confusion_matrix, accuracy_score, model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "in this project i used 4,403 indonesian tweets which are already labeled in 5 categories. that are anger, happy, sadness, fear, and love.\n",
    "\n",
    "dataset credit: https://github.com/meisaputri21/Indonesian-Twitter-Emotion-Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Twitter_Emotion_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anger      1101\n",
       "happy      1017\n",
       "sadness     997\n",
       "fear        649\n",
       "love        637\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data is imbalance, there is difference count in each label\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['label_id'] = le.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger</td>\n",
       "      <td>Soal jln Jatibaru,polisi tdk bs GERTAK gubernur .Emangny polisi tdk ikut pmbhasan? Jgn berpolitik. Pengaturan wilayah,hak gubernur. Persoalan Tn Abang soal turun temurun.Pelik.Perlu kesabaran. [USERNAME] [USERNAME] [URL]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anger</td>\n",
       "      <td>Sesama cewe lho (kayaknya), harusnya bisa lebih rasain lah yang harus sibuk jaga diri, rasain sakitnya haid, dan paniknya pulang malem sendirian. Gimana orang asing? Wajarlah banyak korban yang takut curhat, bukan dibela malah dihujat.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happy</td>\n",
       "      <td>Kepingin gudeg mbarek Bu hj. Amad Foto dari google, sengaja, biar teman-teman jg membayangkannya. Berbagi itu indah.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anger</td>\n",
       "      <td>Jln Jatibaru,bagian dari wilayah Tn Abang.Pengaturan wilayah tgg jwb dan wwnang gub.Tng Abng soal rumit,sejak gub2 , trdahulu.Skrg sedng dibenahi,agr bermnfaat semua pihak.Mohon yg punya otak,berpikirlah dgn wajar,kecuali otaknya butek.Ya kamu. [URL]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happy</td>\n",
       "      <td>Sharing pengalaman aja, kemarin jam 18.00 batalin tiket di stasiun pasar senen, lancar, antrian tidak terlalu rame,15 menitan dan beress semua! Mungkin bisa dicoba twips, di jam-jam segitu  cc [USERNAME]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4396</th>\n",
       "      <td>love</td>\n",
       "      <td>Tahukah kamu, bahwa saat itu papa memejamkan matanya dan menahan gejolak dan batinnya. Bahwa papa sangat ingin mengikuti keinginanmu tapu lagi-lagi dia HARUS menjagamu?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4397</th>\n",
       "      <td>fear</td>\n",
       "      <td>Sulitnya menetapkan Calon Wapresnya Jokowi di Pilpres 2019 salah satunya disebabkan gemuknya partai koalisi yang mengusung petahana. Sehingga sikap kehati-hatian agar tidak ada yang terluka dari partai pengusung harus tetap dijaga #Pilpres2019 #Pilpres #Jokowi #Parpol</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>anger</td>\n",
       "      <td>5. masa depannya nggak jelas. lha iya, gimana mau jelas coba? lulusan seni, bisanya cuma nari, mau kerja apa? nari-nari doang. berapa sih, penghasilannya penari? kerja juga gak tetap~ #dontdateadancer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>happy</td>\n",
       "      <td>[USERNAME] dulu beneran ada mahasiswa Teknik UI nembak pacarnya pas sahur di Kukusan Teknik Depok, diliput kru Katakan Cinta (dan belum pacaran mereka). Sekarang udah nikah dan punya anak. Pernah diceritain laman UI Shitposting/Divarposting juga.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Ya Allah, hanya Engkau yang mengetahui rasa sakit di hati ini. Sembuhkanlah Ya Allah..</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4401 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label  \\\n",
       "0       anger   \n",
       "1       anger   \n",
       "2       happy   \n",
       "3       anger   \n",
       "4       happy   \n",
       "...       ...   \n",
       "4396     love   \n",
       "4397     fear   \n",
       "4398    anger   \n",
       "4399    happy   \n",
       "4400  sadness   \n",
       "\n",
       "                                                                                                                                                                                                                                                                             tweet  \\\n",
       "0                                                     Soal jln Jatibaru,polisi tdk bs GERTAK gubernur .Emangny polisi tdk ikut pmbhasan? Jgn berpolitik. Pengaturan wilayah,hak gubernur. Persoalan Tn Abang soal turun temurun.Pelik.Perlu kesabaran. [USERNAME] [USERNAME] [URL]   \n",
       "1                                      Sesama cewe lho (kayaknya), harusnya bisa lebih rasain lah yang harus sibuk jaga diri, rasain sakitnya haid, dan paniknya pulang malem sendirian. Gimana orang asing? Wajarlah banyak korban yang takut curhat, bukan dibela malah dihujat.   \n",
       "2                                                                                                                                                             Kepingin gudeg mbarek Bu hj. Amad Foto dari google, sengaja, biar teman-teman jg membayangkannya. Berbagi itu indah.   \n",
       "3                       Jln Jatibaru,bagian dari wilayah Tn Abang.Pengaturan wilayah tgg jwb dan wwnang gub.Tng Abng soal rumit,sejak gub2 , trdahulu.Skrg sedng dibenahi,agr bermnfaat semua pihak.Mohon yg punya otak,berpikirlah dgn wajar,kecuali otaknya butek.Ya kamu. [URL]   \n",
       "4                                                                      Sharing pengalaman aja, kemarin jam 18.00 batalin tiket di stasiun pasar senen, lancar, antrian tidak terlalu rame,15 menitan dan beress semua! Mungkin bisa dicoba twips, di jam-jam segitu  cc [USERNAME]   \n",
       "...                                                                                                                                                                                                                                                                            ...   \n",
       "4396                                                                                                      Tahukah kamu, bahwa saat itu papa memejamkan matanya dan menahan gejolak dan batinnya. Bahwa papa sangat ingin mengikuti keinginanmu tapu lagi-lagi dia HARUS menjagamu?   \n",
       "4397  Sulitnya menetapkan Calon Wapresnya Jokowi di Pilpres 2019 salah satunya disebabkan gemuknya partai koalisi yang mengusung petahana. Sehingga sikap kehati-hatian agar tidak ada yang terluka dari partai pengusung harus tetap dijaga #Pilpres2019 #Pilpres #Jokowi #Parpol   \n",
       "4398                                                                      5. masa depannya nggak jelas. lha iya, gimana mau jelas coba? lulusan seni, bisanya cuma nari, mau kerja apa? nari-nari doang. berapa sih, penghasilannya penari? kerja juga gak tetap~ #dontdateadancer   \n",
       "4399                        [USERNAME] dulu beneran ada mahasiswa Teknik UI nembak pacarnya pas sahur di Kukusan Teknik Depok, diliput kru Katakan Cinta (dan belum pacaran mereka). Sekarang udah nikah dan punya anak. Pernah diceritain laman UI Shitposting/Divarposting juga.   \n",
       "4400                                                                                                                                                                                        Ya Allah, hanya Engkau yang mengetahui rasa sakit di hati ini. Sembuhkanlah Ya Allah..   \n",
       "\n",
       "      label_id  \n",
       "0            0  \n",
       "1            0  \n",
       "2            2  \n",
       "3            0  \n",
       "4            2  \n",
       "...        ...  \n",
       "4396         3  \n",
       "4397         1  \n",
       "4398         0  \n",
       "4399         2  \n",
       "4400         4  \n",
       "\n",
       "[4401 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(x):\n",
    "    x = x.strip()\n",
    "    x = x.lower()\n",
    "    x = re.sub(r'\\d+','',x)\n",
    "    x = x.translate(str.maketrans('','', string.punctuation))\n",
    "    stopword = StopWordRemoverFactory().create_stop_word_remover()\n",
    "    x = stopword.remove(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(lambda x: cleaning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anger</td>\n",
       "      <td>soal jln jatibarupolisi tdk bs gertak gubernur emangny polisi tdk ikut pmbhasan jgn berpolitik pengaturan wilayahhak gubernur persoalan tn abang soal turun temurunpelikperlu kesabaran username username url</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anger</td>\n",
       "      <td>sesama cewe lho kayaknya harusnya lebih rasain lah harus sibuk jaga diri rasain sakitnya haid paniknya pulang malem sendirian gimana orang asing wajarlah banyak korban takut curhat bukan dibela malah dihujat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happy</td>\n",
       "      <td>kepingin gudeg mbarek bu hj amad foto google sengaja biar temanteman jg membayangkannya berbagi indah</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anger</td>\n",
       "      <td>jln jatibarubagian wilayah tn abangpengaturan wilayah tgg jwb wwnang gubtng abng soal rumitsejak gub  trdahuluskrg sedng dibenahiagr bermnfaat semua pihakmohon yg punya otakberpikirlah dgn wajarkecuali otaknya butekya kamu url</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>happy</td>\n",
       "      <td>sharing pengalaman aja kemarin jam  batalin tiket stasiun pasar senen lancar antrian terlalu rame menitan beress semua mungkin dicoba twips jamjam segitu  cc username</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4396</th>\n",
       "      <td>love</td>\n",
       "      <td>tahukah kamu saat papa memejamkan matanya menahan gejolak batinnya papa sangat mengikuti keinginanmu tapu lagilagi harus menjagamu</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4397</th>\n",
       "      <td>fear</td>\n",
       "      <td>sulitnya menetapkan calon wapresnya jokowi pilpres  salah satunya disebabkan gemuknya partai koalisi mengusung petahana sikap kehatihatian tidak yang terluka partai pengusung tetap dijaga pilpres pilpres jokowi parpol</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>anger</td>\n",
       "      <td>masa depannya jelas lha iya gimana mau jelas coba lulusan seni bisanya cuma nari mau kerja apa narinari doang berapa sih penghasilannya penari kerja gak tetap dontdateadancer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>happy</td>\n",
       "      <td>username dulu beneran mahasiswa teknik ui nembak pacarnya pas sahur kukusan teknik depok diliput kru katakan cinta belum pacaran sekarang udah nikah punya anak pernah diceritain laman ui shitpostingdivarposting</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>sadness</td>\n",
       "      <td>allah engkau mengetahui rasa sakit hati sembuhkanlah allah</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4401 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label  \\\n",
       "0       anger   \n",
       "1       anger   \n",
       "2       happy   \n",
       "3       anger   \n",
       "4       happy   \n",
       "...       ...   \n",
       "4396     love   \n",
       "4397     fear   \n",
       "4398    anger   \n",
       "4399    happy   \n",
       "4400  sadness   \n",
       "\n",
       "                                                                                                                                                                                                                                   tweet  \\\n",
       "0                          soal jln jatibarupolisi tdk bs gertak gubernur emangny polisi tdk ikut pmbhasan jgn berpolitik pengaturan wilayahhak gubernur persoalan tn abang soal turun temurunpelikperlu kesabaran username username url   \n",
       "1                        sesama cewe lho kayaknya harusnya lebih rasain lah harus sibuk jaga diri rasain sakitnya haid paniknya pulang malem sendirian gimana orang asing wajarlah banyak korban takut curhat bukan dibela malah dihujat   \n",
       "2                                                                                                                                  kepingin gudeg mbarek bu hj amad foto google sengaja biar temanteman jg membayangkannya berbagi indah   \n",
       "3     jln jatibarubagian wilayah tn abangpengaturan wilayah tgg jwb wwnang gubtng abng soal rumitsejak gub  trdahuluskrg sedng dibenahiagr bermnfaat semua pihakmohon yg punya otakberpikirlah dgn wajarkecuali otaknya butekya kamu url   \n",
       "4                                                                 sharing pengalaman aja kemarin jam  batalin tiket stasiun pasar senen lancar antrian terlalu rame menitan beress semua mungkin dicoba twips jamjam segitu  cc username   \n",
       "...                                                                                                                                                                                                                                  ...   \n",
       "4396                                                                                                  tahukah kamu saat papa memejamkan matanya menahan gejolak batinnya papa sangat mengikuti keinginanmu tapu lagilagi harus menjagamu   \n",
       "4397           sulitnya menetapkan calon wapresnya jokowi pilpres  salah satunya disebabkan gemuknya partai koalisi mengusung petahana sikap kehatihatian tidak yang terluka partai pengusung tetap dijaga pilpres pilpres jokowi parpol   \n",
       "4398                                                      masa depannya jelas lha iya gimana mau jelas coba lulusan seni bisanya cuma nari mau kerja apa narinari doang berapa sih penghasilannya penari kerja gak tetap dontdateadancer   \n",
       "4399                  username dulu beneran mahasiswa teknik ui nembak pacarnya pas sahur kukusan teknik depok diliput kru katakan cinta belum pacaran sekarang udah nikah punya anak pernah diceritain laman ui shitpostingdivarposting   \n",
       "4400                                                                                                                                                                          allah engkau mengetahui rasa sakit hati sembuhkanlah allah   \n",
       "\n",
       "      label_id  \n",
       "0            0  \n",
       "1            0  \n",
       "2            2  \n",
       "3            0  \n",
       "4            2  \n",
       "...        ...  \n",
       "4396         3  \n",
       "4397         1  \n",
       "4398         0  \n",
       "4399         2  \n",
       "4400         4  \n",
       "\n",
       "[4401 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Feature and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(df['tweet'])\n",
    "y = np.array(list(df['label_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Train and Data Test Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes - MultinomialNB dan ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling : MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()\n",
    "X_train_c = count_vec.fit_transform(X_train)\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNB\n",
    "mnb_model = MultinomialNB().fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = mnb_model.predict(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91       751\n",
      "           1       0.99      0.71      0.83       468\n",
      "           2       0.93      0.95      0.94       710\n",
      "           3       0.99      0.75      0.85       446\n",
      "           4       0.85      0.96      0.90       705\n",
      "\n",
      "    accuracy                           0.90      3080\n",
      "   macro avg       0.92      0.87      0.89      3080\n",
      "weighted avg       0.91      0.90      0.89      3080\n",
      "\n",
      "\n",
      "\n",
      "confusion matrix\n",
      "[[743   1   2   0   5]\n",
      " [ 66 334  13   2  53]\n",
      " [ 17   1 675   2  15]\n",
      " [ 27   0  35 333  51]\n",
      " [ 27   0   0   1 677]]\n",
      "\n",
      "\n",
      "classification report\n",
      "0.8967532467532467\n"
     ]
    }
   ],
   "source": [
    "print('classification report')\n",
    "print(classification_report(y_train,y_train_pred))\n",
    "print('\\n')\n",
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_train,y_train_pred))\n",
    "print('\\n')\n",
    "print('classification report')\n",
    "print(accuracy_score(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()\n",
    "X_test_c = count_vec.fit_transform(X_test)\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "X_test_tfidf = tfidf.fit_transform(X_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_model = MultinomialNB().fit(X_test_tfidf,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = mnb_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87       350\n",
      "           1       0.99      0.55      0.70       181\n",
      "           2       0.98      0.95      0.97       307\n",
      "           3       0.98      0.81      0.89       191\n",
      "           4       0.89      0.95      0.92       292\n",
      "\n",
      "    accuracy                           0.89      1321\n",
      "   macro avg       0.92      0.85      0.87      1321\n",
      "weighted avg       0.90      0.89      0.88      1321\n",
      "\n",
      "\n",
      "\n",
      "confusion matrix\n",
      "[[349   1   0   0   0]\n",
      " [ 59  99   4   3  16]\n",
      " [ 13   0 293   0   1]\n",
      " [ 16   0   3 154  18]\n",
      " [ 16   0   0   0 276]]\n",
      "\n",
      "\n",
      "classification report\n",
      "0.886449659348978\n"
     ]
    }
   ],
   "source": [
    "print('classification report')\n",
    "print(classification_report(y_test,y_test_pred))\n",
    "print('\\n')\n",
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_test,y_test_pred))\n",
    "print('\\n')\n",
    "print('classification report')\n",
    "print(accuracy_score(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling : ComplementNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()\n",
    "X_train_c = count_vec.fit_transform(X_train)\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnb_model = ComplementNB().fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = cnb_model.predict(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       751\n",
      "           1       0.98      0.98      0.98       468\n",
      "           2       0.99      0.97      0.98       710\n",
      "           3       0.96      0.98      0.97       446\n",
      "           4       0.98      0.96      0.97       705\n",
      "\n",
      "    accuracy                           0.98      3080\n",
      "   macro avg       0.98      0.98      0.98      3080\n",
      "weighted avg       0.98      0.98      0.98      3080\n",
      "\n",
      "\n",
      "\n",
      "confusion matrix\n",
      "[[746   2   1   0   2]\n",
      " [  2 457   3   3   3]\n",
      " [ 10   2 686   6   6]\n",
      " [  4   4   2 435   1]\n",
      " [ 16   1   0   8 680]]\n",
      "\n",
      "\n",
      "classification report\n",
      "0.9753246753246754\n"
     ]
    }
   ],
   "source": [
    "print('classification report')\n",
    "print(classification_report(y_train,y_train_pred))\n",
    "print('\\n')\n",
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_train,y_train_pred))\n",
    "print('\\n')\n",
    "print('classification report')\n",
    "print(accuracy_score(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()\n",
    "X_test_c = count_vec.fit_transform(X_test)\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "X_test_tfidf = tfidf.fit_transform(X_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnb_model = ComplementNB().fit(X_test_tfidf,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = cnb_model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       350\n",
      "           1       0.99      0.98      0.99       181\n",
      "           2       1.00      0.99      0.99       307\n",
      "           3       0.98      1.00      0.99       191\n",
      "           4       1.00      0.98      0.99       292\n",
      "\n",
      "    accuracy                           0.99      1321\n",
      "   macro avg       0.99      0.99      0.99      1321\n",
      "weighted avg       0.99      0.99      0.99      1321\n",
      "\n",
      "\n",
      "\n",
      "confusion matrix\n",
      "[[348   2   0   0   0]\n",
      " [  1 178   0   1   1]\n",
      " [  3   0 303   1   0]\n",
      " [  0   0   0 191   0]\n",
      " [  4   0   1   2 285]]\n",
      "\n",
      "\n",
      "classification report\n",
      "0.987887963663891\n"
     ]
    }
   ],
   "source": [
    "print('classification report')\n",
    "print(classification_report(y_test,y_test_pred))\n",
    "print('\\n')\n",
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_test,y_test_pred))\n",
    "print('\\n')\n",
    "print('classification report')\n",
    "print(accuracy_score(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "1. MultinomialNB\n",
    "    - Data Train prediction performance : 0.89675\n",
    "    - Data Test prediction performance : 0.88645\n",
    "\n",
    "2. ComplementNB\n",
    "    - Data Train prediction performance : 0.97533\n",
    "    - Data Test prediction performance : 0.98788\n",
    "\n",
    "based on the classification report of both type of naive bayes algorithm, we know that both algorithm performed well. There isn't too much differences between train and test performance accuracy. But here, ComplementNB are better than MultinomialNB. MultinomialNB is an adaptation of the standard Multinomial Naive Bayes that is particulary suited for this imbalance data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
